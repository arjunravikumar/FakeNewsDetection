{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup,RobertaForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNews = pd.read_csv('OutputFiles/TrainNews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>the head of a conservative republican faction ...</td>\n",
       "      <td>as u s budget fight looms republicans flip the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>transgender people will be allowed for the fir...</td>\n",
       "      <td>u s military to accept transgender recruits on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>the special counsel investigation of links bet...</td>\n",
       "      <td>senior u s republican senator let mr mueller d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>trump campaign adviser george papadopoulos tol...</td>\n",
       "      <td>fbi russia probe helped by australian diplomat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>president donald trump called on the u s posta...</td>\n",
       "      <td>trump wants postal service to charge much more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>0</td>\n",
       "      <td>21st century wire says as 21wire reported earl...</td>\n",
       "      <td>mcpain john mccain furious that iran treated u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>0</td>\n",
       "      <td>21st century wire says it s a familiar theme w...</td>\n",
       "      <td>justice yahoo settles e mail privacy class act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>0</td>\n",
       "      <td>patrick henningsen 21st century wireremember w...</td>\n",
       "      <td>sunnistan us and allied safe zone plan to take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>0</td>\n",
       "      <td>21st century wire says al jazeera america will...</td>\n",
       "      <td>how to blow 700 million al jazeera america fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>0</td>\n",
       "      <td>21st century wire says as 21wire predicted in ...</td>\n",
       "      <td>10 u s navy sailors held by iranian military s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "0          1  the head of a conservative republican faction ...   \n",
       "1          1  transgender people will be allowed for the fir...   \n",
       "2          1  the special counsel investigation of links bet...   \n",
       "3          1  trump campaign adviser george papadopoulos tol...   \n",
       "4          1  president donald trump called on the u s posta...   \n",
       "...      ...                                                ...   \n",
       "44893      0  21st century wire says as 21wire reported earl...   \n",
       "44894      0  21st century wire says it s a familiar theme w...   \n",
       "44895      0  patrick henningsen 21st century wireremember w...   \n",
       "44896      0  21st century wire says al jazeera america will...   \n",
       "44897      0  21st century wire says as 21wire predicted in ...   \n",
       "\n",
       "                                                   title  \n",
       "0      as u s budget fight looms republicans flip the...  \n",
       "1      u s military to accept transgender recruits on...  \n",
       "2      senior u s republican senator let mr mueller d...  \n",
       "3      fbi russia probe helped by australian diplomat...  \n",
       "4      trump wants postal service to charge much more...  \n",
       "...                                                  ...  \n",
       "44893  mcpain john mccain furious that iran treated u...  \n",
       "44894  justice yahoo settles e mail privacy class act...  \n",
       "44895  sunnistan us and allied safe zone plan to take...  \n",
       "44896  how to blow 700 million al jazeera america fin...  \n",
       "44897  10 u s navy sailors held by iranian military s...  \n",
       "\n",
       "[44898 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNews = trainNews[trainNews.text.str.len() >= 5]\n",
    "\n",
    "trainNews['fullNewsText'] = trainNews['title'] + \". \" + trainNews['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>fullNewsText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>the head of a conservative republican faction ...</td>\n",
       "      <td>as u s budget fight looms republicans flip the...</td>\n",
       "      <td>as u s budget fight looms republicans flip the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>transgender people will be allowed for the fir...</td>\n",
       "      <td>u s military to accept transgender recruits on...</td>\n",
       "      <td>u s military to accept transgender recruits on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>the special counsel investigation of links bet...</td>\n",
       "      <td>senior u s republican senator let mr mueller d...</td>\n",
       "      <td>senior u s republican senator let mr mueller d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>trump campaign adviser george papadopoulos tol...</td>\n",
       "      <td>fbi russia probe helped by australian diplomat...</td>\n",
       "      <td>fbi russia probe helped by australian diplomat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>president donald trump called on the u s posta...</td>\n",
       "      <td>trump wants postal service to charge much more...</td>\n",
       "      <td>trump wants postal service to charge much more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>0</td>\n",
       "      <td>21st century wire says as 21wire reported earl...</td>\n",
       "      <td>mcpain john mccain furious that iran treated u...</td>\n",
       "      <td>mcpain john mccain furious that iran treated u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>0</td>\n",
       "      <td>21st century wire says it s a familiar theme w...</td>\n",
       "      <td>justice yahoo settles e mail privacy class act...</td>\n",
       "      <td>justice yahoo settles e mail privacy class act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>0</td>\n",
       "      <td>patrick henningsen 21st century wireremember w...</td>\n",
       "      <td>sunnistan us and allied safe zone plan to take...</td>\n",
       "      <td>sunnistan us and allied safe zone plan to take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>0</td>\n",
       "      <td>21st century wire says al jazeera america will...</td>\n",
       "      <td>how to blow 700 million al jazeera america fin...</td>\n",
       "      <td>how to blow 700 million al jazeera america fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>0</td>\n",
       "      <td>21st century wire says as 21wire predicted in ...</td>\n",
       "      <td>10 u s navy sailors held by iranian military s...</td>\n",
       "      <td>10 u s navy sailors held by iranian military s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44265 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text  \\\n",
       "0          1  the head of a conservative republican faction ...   \n",
       "1          1  transgender people will be allowed for the fir...   \n",
       "2          1  the special counsel investigation of links bet...   \n",
       "3          1  trump campaign adviser george papadopoulos tol...   \n",
       "4          1  president donald trump called on the u s posta...   \n",
       "...      ...                                                ...   \n",
       "44893      0  21st century wire says as 21wire reported earl...   \n",
       "44894      0  21st century wire says it s a familiar theme w...   \n",
       "44895      0  patrick henningsen 21st century wireremember w...   \n",
       "44896      0  21st century wire says al jazeera america will...   \n",
       "44897      0  21st century wire says as 21wire predicted in ...   \n",
       "\n",
       "                                                   title  \\\n",
       "0      as u s budget fight looms republicans flip the...   \n",
       "1      u s military to accept transgender recruits on...   \n",
       "2      senior u s republican senator let mr mueller d...   \n",
       "3      fbi russia probe helped by australian diplomat...   \n",
       "4      trump wants postal service to charge much more...   \n",
       "...                                                  ...   \n",
       "44893  mcpain john mccain furious that iran treated u...   \n",
       "44894  justice yahoo settles e mail privacy class act...   \n",
       "44895  sunnistan us and allied safe zone plan to take...   \n",
       "44896  how to blow 700 million al jazeera america fin...   \n",
       "44897  10 u s navy sailors held by iranian military s...   \n",
       "\n",
       "                                            fullNewsText  \n",
       "0      as u s budget fight looms republicans flip the...  \n",
       "1      u s military to accept transgender recruits on...  \n",
       "2      senior u s republican senator let mr mueller d...  \n",
       "3      fbi russia probe helped by australian diplomat...  \n",
       "4      trump wants postal service to charge much more...  \n",
       "...                                                  ...  \n",
       "44893  mcpain john mccain furious that iran treated u...  \n",
       "44894  justice yahoo settles e mail privacy class act...  \n",
       "44895  sunnistan us and allied safe zone plan to take...  \n",
       "44896  how to blow 700 million al jazeera america fin...  \n",
       "44897  10 u s navy sailors held by iranian military s...  \n",
       "\n",
       "[44265 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNews = trainNews.drop(['title', 'text'], axis=1)\n",
    "trainNews = trainNews.sort_values(by=['fullNewsText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNews.to_csv(\"OutputFiles/FinalTrainNews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validData = pd.read_csv(\"OriginalInputFiles/news.csv\")\n",
    "validData = validData.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "encode_label = {'FAKE' : 0, 'REAL' : 1}\n",
    "\n",
    "validData = validData[validData.text.str.len() >= 5]\n",
    "\n",
    "validData['label'] = validData['label'].map(encode_label)\n",
    "validData['fullNewsText'] = validData['title'] + \". \" + validData['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validData = validData.drop(['title', 'text'], axis=1)\n",
    "validData.to_csv(\"OutputFiles/FinalValidNews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNewsSentences = trainNews[\"fullNewsText\"].values\n",
    "targetLabels = trainNews[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validNewsSentences = validData[\"fullNewsText\"].values\n",
    "validLabels = validData[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "RoBERTa loaded\n"
     ]
    }
   ],
   "source": [
    "robertaModel = RobertaForSequenceClassification.from_pretrained(\"roberta-base\",\n",
    "                                                                    num_labels = 2,\n",
    "                                                                    output_attentions = False,\n",
    "                                                                    output_hidden_states = False)\n",
    "robertaTokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)\n",
    "print('RoBERTa loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "def convertToTensor(newsSentences,labels):\n",
    "    idsRoberta = []\n",
    "    robertaMasks = []\n",
    "    newsIDs = []\n",
    "    counter = 0\n",
    "    for news in newsSentences:\n",
    "        robertaEncoded = robertaTokenizer.encode_plus(news,add_special_tokens = True,max_length = 512,\n",
    "                                                             pad_to_max_length = True,\n",
    "                                                             return_attention_mask = True,\n",
    "                                                             return_tensors = 'pt')\n",
    "        idsRoberta.append(robertaEncoded['input_ids'])\n",
    "        robertaMasks.append(robertaEncoded['attention_mask'])\n",
    "        newsIDs.append(counter)\n",
    "        counter+=1\n",
    "\n",
    "    idsRoberta = torch.cat(idsRoberta, dim=0)\n",
    "    robertaMasks = torch.cat(robertaMasks, dim=0)\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    tensonDataset = TensorDataset(idsRoberta, robertaMasks, labels)\n",
    "    return tensonDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "trainTensor = convertToTensor(trainNewsSentences,targetLabels)\n",
    "validTensor = convertToTensor(validNewsSentences,validLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "batchSize = 32\n",
    "trainDataloader = DataLoader(trainTensor,sampler = RandomSampler(trainTensor),\n",
    "                                      batch_size = batchSize)\n",
    "validationDataloader = DataLoader(validTensor,sampler = SequentialSampler(validTensor)\n",
    "                                  ,batch_size = batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(robertaModel.parameters(),lr = 5e-5,eps = 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs = 2\n",
    "totalSteps = len(trainDataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0,\n",
    "                                                    num_training_steps = totalSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def getAccuracy(preds, labels):\n",
    "    flatPredictions = np.argmax(preds, axis=1).flatten()\n",
    "    flatLabels = labels.flatten()\n",
    "    return np.sum(flatPredictions == flatLabels) / len(flatLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed_val = 100\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "\n",
    "roberta_training_stats = []\n",
    "\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    robertaModel.train()\n",
    "\n",
    "    for step, batch in enumerate(roberta_train_dataloader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(roberta_train_dataloader), elapsed))\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        roberta_model.zero_grad()        \n",
    "        loss, logits = roberta_model(b_input_ids, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(roberta_model.parameters(), 1.0)\n",
    "        roberta_optimizer.step()\n",
    "        roberta_scheduler.step()\n",
    "    avg_train_loss = total_train_loss / len(roberta_train_dataloader)            \n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    roberta_model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    for batch in roberta_validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        with torch.no_grad():        \n",
    "            (loss, logits) = roberta_model(b_input_ids, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        total_eval_loss += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    avg_val_accuracy = total_eval_accuracy / len(roberta_validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    avg_val_loss = total_eval_loss / len(roberta_validation_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "    roberta_training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
